{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>The Iptables Add-on allows Splunk data administrators to map netfilter events to the CIM enabling the data to be used with other Splunk Apps.</p> <p>This Splunk Add-on is community driven. Any issues or feature requests may be submitted directly through Github.</p>"},{"location":"#assumptions","title":"Assumptions","text":"<p>This documentation assumes the following:</p> <ol> <li>You have a linux server with the appropriate firewall tools installed.</li> <li>You have a working Splunk environment.</li> <li>Basic understanding of Splunk, linux, and Firewalld/UFW/Iptables.</li> </ol>"},{"location":"#about","title":"About","text":"Info Description Version 1.3.8 - Splunkbase | GitHub Vendor Products REHL/CentOS - Firewalld, Ubuntu - UFW, built-in IPtables Add-on has a web UI No, this add-on does not include views. <p>Get Started</p>"},{"location":"getting-started/prepare-logs-for-splunk/","title":"Prepare Logs for Splunk","text":"<p>Optional</p>"},{"location":"getting-started/prepare-logs-for-splunk/#syslog-setup","title":"Syslog Setup","text":"<p>To simplify logging of linux firewall events it is recommended to utilize rsyslog, syslog-ng, or a similar tool to separate firewall events into a new file for Splunk to monitor.</p> <p>Refer to the vender specific documentation on the best-practices to accomplish this. A simple example using rsyslog is demonstrated below.</p> Rsyslog Example <pre><code># Example configuration file\n# /etc/rsyslog.d/10-iptables.conf\n# Log iptables log messages to file\n:msg,regex,\"IN=[^\\=]*OUT=\" /var/log/iptables.log\n\n# The following stops logging anything that matches the last rule to the original file being logged to.\n&amp; stop\n</code></pre> <p>Note</p> <p>Verify the created file will have sufficient privileges for Splunk to monitor the file.</p>"},{"location":"getting-started/prepare-logs-for-splunk/#log-prefix","title":"Log Prefix","text":"<p>By default UFW and Firewalld use their own log prefixes:</p> Firewall Prefix Example UFW <code>[UFW *]</code> <code>[UFW ALLOW] IN= OUT=eth0 SRC=192.168.0.15 DST=192.168.0.16 LEN=76 TOS=0x10 PREC=0x00 TTL=64 ID=32137 DF PROTO=UDP SPT=36231 DPT=123 LEN=56</code> Firewalld <code>*_DROP</code> or <code>*_REJECT</code> <code>FINAL_REJECT: IN=ens192 OUT= MAC= SRC=10.0.10.10 DST=10.0.10.21 LEN=328 TOS=0x00 PREC=0x00 TTL=57 ID=4162 PROTO=UDP SPT=53483 DPT=38811 LEN=308</code> <p>If custom log prefixes are being used, additional setup may be required for this add-on to work appropriately. See Using Custom Log Prefixes in this documentation for more information.</p>"},{"location":"getting-started/where-to-install/","title":"Where to Install","text":"<p>For detailed information on where to install Splunk Apps/add-ons, including best practices, can be found at Splunk Docs: About Installing Splunk add-ons</p>"},{"location":"getting-started/where-to-install/#standalone-deployments","title":"Standalone Deployments","text":"<p>Install this add-on to the single instance. For more information see Splunk Docs: Install add-on in a single-instance Splunk deployment</p>"},{"location":"getting-started/where-to-install/#distributed-deployments","title":"Distributed Deployments","text":"Splunk Instance type Supported Required Comments Search Heads Yes Yes Install this add-on to all search heads. Indexers Yes Conditional Not required if heavy forwarders are used to collect data, required if not. Heavy Forwarders Yes Conditional Required, if HFs are used to collect this data source. Universal Forwarders Yes No This add-on does not contain any configurations for a Universal Forwarder. <p>The installation steps for deploying Apps/add-ons in a distributed environment can be found at Splunk Docs: Install an add-on in a distributed Splunk deployment</p>"},{"location":"getting-started/where-to-install/#distributed-deployment-compatibility","title":"Distributed Deployment Compatibility","text":"Distributed deployment feature Supported Comments Search Head Clusters Yes You can install this add-on to a search head cluster. Indexer Clusters Yes You can install this add-on to a indexer cluster. Deployment Server Yes You can use a deployment server to push this add-on to Splunk Universal Forwarders. <p>* For more information, see Splunk's documentation on installing Add-ons.</p>"},{"location":"getting-started/configure-inputs/configure-inputs/","title":"Configure Splunk Input","text":"<p>Objective: Set the sourcetype to <code>linux:iptables</code> in the inputs.conf file on the forwarder.</p>"},{"location":"getting-started/configure-inputs/configure-inputs/#create-a-new-index","title":"Create a new index","text":"<p>Optional Step</p> <p>If you do not wish to create a new index, skip to Splunk Universal Forwarder Configuration.</p> <p>Splunk stores data in indexes. This add-on may be configured to send to a custom event index instead of the default index, main. For more information and steps to create a new index, see Splunk Docs: Create events indexes.</p>"},{"location":"getting-started/configure-inputs/configure-inputs/#purpose-for-creating-a-new-index","title":"Purpose for Creating a new index","text":"<p>The out of the box Splunk configuration stores all data in the default index, main. It is encouraged to create a new index to ensure optimal performance, for setting retention policies, and for providing stricter access controls. For more information about how Splunk indexes work with add-ons, see Splunk Docs: Add-ons and indexes.</p>"},{"location":"getting-started/configure-inputs/configure-inputs/#splunk-universal-forwarder-configuration","title":"Splunk Universal Forwarder Configuration","text":"<p>Download the latest Splunk Universal Forwarder (UF) appropriate for your server.</p> <p>Note</p> <p>Unless utilizing a syslog server, this UF should be installed on the same server that you wish to collect linux firewall events from.</p> <p>Install the UF according to Splunk Docs: Install the Universal Forwarder.</p> <p>Once installed the configurations can be made. The following is a sample inputs.conf that can be pushed using a deployment server or configured on the UF itself.</p> inputs.conf<pre><code>[monitor:///var/log/iptables.log]\ndisabled = 0\nsourcetype = linux:iptables\n# optionally specify an index, if configured.\nindex = osnixfw\n</code></pre> <p>The above assumes the iptable logs have been split into a separate file (see Prepare Logs for Splunk). If the iptable logs are mixed with other linux logs, then use the following sample configuration as a guide.</p>"},{"location":"getting-started/configure-inputs/configure-inputs/#mixed-logs","title":"Mixed Logs","text":"inputs.conf - for mixed logs<pre><code>[monitor:///var/log/syslog]\ndisabled = 0\nsourcetype = syslog\n# optionally specify an index, if configured.\nindex = osnix\n</code></pre> <p>Then create a local directory within this app and add a props.conf to transform the sourcetype to the correct sourcetype.</p> local/props.conf - needed for mixed logs<pre><code>[syslog]\nTRANSFORMS-iptables_sourcetyper = iptables_sourcetyper\n</code></pre> <p>This will enable a prebuilt transforms to automatically sourcetype these logs.</p> <p>Push the configuration to the forwarder, if using a deployment server, or restart the UF if configuring on the UF itself.</p>"},{"location":"getting-started/configure-inputs/configure-inputs/#verify","title":"Verify","text":"<p>Verify the setup has completed successfully by navigating to Splunk web and running a search similar to the following:</p> <pre><code>index=&lt;chosen index&gt; sourcetype=linux:iptables\n</code></pre> <p>If you see data then you are all set! If you are not seeing your data, see Troubleshooting Monitoring Inputs.</p>"},{"location":"getting-started/troubleshooting/troubleshoot-inputs/","title":"Troubleshoot Monitoring Inputs","text":"<p>There is a variety of issues when getting new data into Splunk. Below are a few of the most common issues:</p> Issue Description Solution Splunk cannot read the file If the user running Splunk (default is <code>splunk</code>) cannot read the contents of the file, the data will not be sent to Splunk. log in as the Splunk user and verify the contents can be read. If not, update the permissions of the file to allow read access to the Splunk user. Incorrect timestamps Having the incorrect time setup on either the Splunk instance or the linux server may result in not ingesting the data. In Splunk web, try switching the time range to \"All Time\" when looking for the event data. If the data is found and the incorrect time is observed, update the servers to the correct time and consider utilizing a NTP server for proper time synchronization. Splunk Forwarder communication It is possible that the Splunk Universal Forwarder does not have a connection to the Splunk instance. Verify connection by running the following command on the universal forwarder: <code>$SPLUNK_HOME/bin/splunk list forward-server</code>. $SPLUNK_HOME is the installation directory. The output from this command will show active/inactive connections to the Splunk Instance. Alternatively the internal logs can be searched in Splunk Web. Run the following command on the search head: <code>index=_internal source=*metrics.log* tcpin_connections | stats count by sourceIp</code>. The output of this search will show a list of sources connecting to the Splunk Instance. <p>For more troubleshooting steps, see Splunk Docs: Troubleshooting Data.</p>"},{"location":"guides/guide-custom-log-prefix/","title":"Custom Log Prefix","text":"<p>If you wish to utilize custom log prefixes for use cases, additional setup will be needed for this add-on to properly identify events.</p> <p>This add-on uses the following to map events to their appropriate CIM-compliant action. The action field is important for the Network Traffic data model. If the log prefix does not match your events, the action will be \"unknown.\"</p> Log Prefix Action *allow* allowed *block* blocked *drop* blocked *accept* allowed *reject* blocked *permit* allowed *deny* blocked *denied* blocked <p>the wildcard character (*) is used to find any match with the contained value in the <code>log_prefix</code> field.</p>"},{"location":"guides/guide-custom-log-prefix/#use-your-own-log-prefix","title":"Use your own log prefix","text":"<p>It is recommended to use the log prefixes in the above table somewhere in your custom log prefix so no extra work is needed.</p> Example <p>\"allow_ssh_connections\" or \"telnet_drop\"</p>"},{"location":"guides/guide-custom-log-prefix/#add-new-log-prefix-definition","title":"Add new log prefix definition","text":"<p>If the above table defaults do not work for your use case, another lookup can be created with the correct values to fit your situation.</p> Why use a new lookup file? <p>If the existing lookup file is used, it will be overwritten during future updates. To preserve changes, a new lookup file must be created.</p> <p>It may be easiest to to utilize the linux command line to copy the lookup file, <code>iptables_action.csv</code> located in the <code>lookups</code> directory within this add-on.</p> Example <pre><code>cp lookups/iptables_actions.csv lookups/iptables_custom_actions.csv\n</code></pre> <p>From there you can update the file to fit your use case.</p> Updating lookup example <pre><code>log_prefix,action\n*mycustom_allow*,allowed\n*custom_reject*,blocked\n*custom_drop*,blocked\n</code></pre> <p>It is recommended to have the action field mapped to the Network Traffic datamodel action field (allowed, blocked, teardown). Wrapping the <code>log_prefix</code> field in wildcards (*) gives the flexibility of not having to specify exact values.</p>"},{"location":"guides/guide-custom-log-prefix/#update-transformsconf","title":"Update transforms.conf","text":"<p>After the custom lookup file has been updated, the transforms.conf file will need to be updated to the correct filename.</p> <p>Within the add-on, create a new file in <code>local/transforms.conf</code> (you may have to create the local directory). Next add the following to the file:</p> local/transforms.conf<pre><code>[iptables_action_lookup]\n# If you followed the above example you would\n# set this to \"iptables_custom_actions.csv\" (without quotations).\nfilename = &lt;your_new_file.csv&gt;\n</code></pre> <p>Once the change has been made it may take a few minutes for the changes to take effect. If you don't want to wait you can append <code>| extract reload=true</code> to your Splunk search to force a reload of the configurations. You should now see the correct actions being populated and no longer will show \"unknown.\"</p>"},{"location":"reference/reference-lookups/","title":"Lookup table files","text":"<p>This add-on uses a few CSV lookup files to enrich the data. See below for more information on the lookups used.</p> Lookup Lookup definition Description iptables_action.csv iptables_action_lookup Used to map events to their appropriate action. This utilizes default Firewalld and UFW log prefixes. Custom log prefixes will need to be setup for this to work see Using custom log prefixes for more information. iptables_frametypes.csv iptables_frametypes_lookup Maps Frame Type codes to their descriptive value. iptables_icmp_codes.csv iptables_icmp_codes_lookup Maps ICMP codes to their descriptive value. iptables_transport.csv iptables_transport_lookup Used to map the transport field to the CIM-compliant value."},{"location":"reference/reference-sourcetypes/","title":"Sourcetype","text":"Sourcetype Description CIM Data Models <code>linux:iptables</code> Linux firewall events Network Traffic"},{"location":"reference/releases/","title":"Release Notes for the Linux Iptables Add-on for Splunk","text":""},{"location":"reference/releases/#v138-jul-8-2022","title":"v1.3.8 Jul 8, 2022","text":""},{"location":"reference/releases/#new","title":"New","text":"<ul> <li>Added sample configuration for the syslog sourcetype if IPtable data is mixed with syslog data.</li> </ul>"},{"location":"reference/releases/#updated","title":"Updated","text":"<ul> <li>Updated log_prefix field extraction to consider log prefixes surrounded with quotes.</li> </ul>"},{"location":"reference/releases/release-history/","title":"Release history for the Linux Iptables Add-on for Splunk","text":"<p>The latest version of the Pi-hole DNS app for Splunk is version 1.3.8. See Release notes for the Linux Iptables Add-on for Splunk of the latest version.</p>"},{"location":"reference/releases/release-history/#v137-aug-20-2021","title":"v1.3.7 Aug 20, 2021","text":"<ul> <li>fixed incorrect app value for UFW events - #5</li> <li>updated regex for different UFW log formats - #8</li> </ul>"},{"location":"reference/releases/release-history/#v136-july-20-2021","title":"v1.3.6 July 20, 2021","text":"<p>Notice</p> <p>This updated simplifies the number of sourcetypes down to a single sourcetype (linux:iptables). Any existing reports/alerts/views that are utilizing the old sourcetypes (\"linux:iptables:ufw\" or \"linux:iptables:firewalld\") will be impacted. Verify before updating to this version.</p> <ul> <li>added support for firewalld rich rules - #2</li> <li>updated to only use the single sourcetype, 'linux:iptables'</li> <li>updated action lookup to use wildcards</li> </ul>"},{"location":"reference/releases/release-history/#v135-nov-2-2020","title":"v1.3.5 Nov 2, 2020","text":"<ul> <li>Adding support for Splunk Cloud</li> </ul>"}]}